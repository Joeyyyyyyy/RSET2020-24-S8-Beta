{"cells":[{"cell_type":"code","source":["from google.colab import drive\n","drive.mount('/content/drive/')\n","\n","root_dir = \"/content/drive/MyDrive/\"\n","#import os\n","#os.chdir(root_dir + 'nuswide/nuswide/')"],"metadata":{"id":"8ppYu6BL62xE"},"id":"8ppYu6BL62xE","execution_count":null,"outputs":[]},{"cell_type":"code","execution_count":null,"id":"f571ece1","metadata":{"id":"f571ece1"},"outputs":[],"source":["import pandas as pd\n","import re\n","from nltk.corpus import stopwords\n","from nltk.tokenize import word_tokenize\n","\n","df = pd.read_csv('/content/drive/MyDrive/Project/Final_Dataset/notebooks/proposed model/nuswide/nuswide2_modified.csv')\n","\n","\n","def preprocess_text(text):\n","    if pd.isna(text):\n","        return ''\n","\n","    text = re.sub(r'http\\S+', '', text)\n","    text = re.sub(r'[^a-zA-Z\\s]', '', text)\n","    text = text.lower()\n","    text = re.sub('\\s+', ' ', text).strip()\n","    return text\n","\n","\n","df['Text'] = df['Text'].apply(preprocess_text)\n","\n","df.to_csv('/content/drive/MyDrive/Project/Final_Dataset/notebooks/proposed model/nuswide/preprocessed_file (1).csv', index=False)\n","\n","####################################################\n","####################################################\n","\n","import pandas as pd\n","\n","file_path = '/content/drive/MyDrive/Project/Final_Dataset/notebooks/proposed model/nuswide/preprocessed_file (1).csv'\n","\n","df = pd.read_csv(file_path)\n","\n","df = df.dropna(subset=['Text'], how='any')\n","df = df.drop_duplicates(subset=['Text'])\n","\n","\n","df.to_csv('/content/drive/MyDrive/Project/Final_Dataset/notebooks/proposed model/nuswide/cleaned_file.csv', index=False)\n"]},{"cell_type":"code","execution_count":null,"id":"1cc9fe35","metadata":{"id":"1cc9fe35","outputId":"022094a5-f926-4d20-efbc-45bb7b0d9360","colab":{"base_uri":"https://localhost:8080/"}},"outputs":[{"output_type":"stream","name":"stdout","text":["         File Name   domain                  Text  \\\n","0  0426_2285945634  airport      ready for takeof   \n","1   0671_483048408  airport   busy airport hustle   \n","2   0465_247609520  airport  waiting for boarding   \n","3  0540_2218117161  airport    airport adventures   \n","4  0334_2114912741  airport           flying high   \n","\n","                                             Hashtag  Pre_hashtags  \\\n","0                 #avgeek #pilot #travel #plane #fly           NaN   \n","1  #aviation #aviationlovers #boeing #aircraft #a...           NaN   \n","2  #flying #airplane #instagramaviation #planespo...           NaN   \n","3  #instaplane #flight #aviationdaily #cabincrew ...           NaN   \n","4  #airline #aviationgeek #planespotter #pilotlif...           NaN   \n","\n","                                         Pre_hashtag  \n","0                  avgeek  pilot  travel  plane  fly  \n","1  aviation  aviationlovers  boeing  aircraft  av...  \n","2  flying  airplane  instagramaviation  planespot...  \n","3  instaplane  flight  aviationdaily  cabincrew  ...  \n","4  airline  aviationgeek  planespotter  pilotlife...  \n"]}],"source":["import pandas as pd\n","\n","# Load the CSV file into a DataFrame\n","df = pd.read_csv('/content/drive/MyDrive/Project/Final_Dataset/notebooks/proposed model/nuswide/cleaned_file.csv')\n","\n","# Remove the \"#\" symbol and join the hashtags into a single string\n","df['Pre_hashtag'] = df['Hashtag'].apply(lambda x: ' '.join(x.split('#')[1:]))\n","\n","# Print the DataFrame to verify the changes\n","print(df.head())\n","\n","# Save the modified DataFrame back to a CSV file\n","df.to_csv('/content/drive/MyDrive/Project/Final_Dataset/notebooks/proposed model/nuswide/modified_file (1).csv', index=False)\n"]},{"cell_type":"code","source":["import csv\n","import random\n","\n","# Read the CSV file\n","with open('/content/drive/MyDrive/Project/Final_Dataset/notebooks/proposed model/nuswide/modified_file (1).csv', 'r') as file:\n","    reader = csv.reader(file)\n","    rows = list(reader)\n","\n","# Shuffle the rows excluding the first row\n","header = rows[0]\n","data = rows[1:]\n","random.shuffle(data)\n","\n","# Write the shuffled data back to the CSV file\n","with open('/content/drive/MyDrive/Project/Final_Dataset/notebooks/proposed model/nuswide/modified_file(1)_shuffled_file.csv', 'w', newline='') as file:\n","    writer = csv.writer(file)\n","    writer.writerow(header)\n","    writer.writerows(data)\n","\n","print(\"Rows shuffled successfully!\")"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"rm3MufUsWm2e","outputId":"49b50d1e-2451-49fd-844a-6d71daf2c572"},"id":"rm3MufUsWm2e","execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Rows shuffled successfully!\n"]}]},{"cell_type":"code","execution_count":null,"id":"49c43751","metadata":{"id":"49c43751","outputId":"bbd74903-2171-44ad-e9a7-0d890cbd71a2","colab":{"base_uri":"https://localhost:8080/"}},"outputs":[{"output_type":"stream","name":"stdout","text":["Downloading data from https://storage.googleapis.com/tensorflow/keras-applications/inception_v3/inception_v3_weights_tf_dim_ordering_tf_kernels.h5\n","96112376/96112376 [==============================] - 1s 0us/step\n","1\n","2\n","3\n","4\n","5\n","6\n","7\n","8\n","9\n","10\n","11\n","12\n","13\n","14\n","15\n","16\n","17\n","18\n","19\n","20\n","21\n","22\n","23\n","24\n","25\n","26\n","27\n","28\n","29\n","30\n","31\n","32\n","33\n","34\n","35\n","36\n","37\n","38\n","39\n","40\n","41\n","42\n","43\n","44\n","45\n","46\n","47\n","48\n","49\n","50\n","51\n","52\n","53\n","54\n","55\n","56\n","57\n","58\n","59\n","60\n","61\n","62\n","63\n","64\n","65\n","66\n","67\n","68\n","69\n","70\n","71\n","72\n","73\n","74\n","75\n","76\n","77\n","78\n","79\n","80\n","81\n","82\n","83\n","84\n","85\n","86\n","87\n","88\n","89\n","90\n","91\n","92\n","93\n","94\n","95\n","96\n","97\n","98\n","99\n","100\n","101\n","102\n","103\n","104\n","105\n","106\n","107\n","108\n","109\n","110\n","111\n","112\n","113\n","114\n","115\n","116\n","117\n","118\n","119\n","120\n","121\n","122\n","123\n","124\n","125\n","126\n","127\n","128\n","129\n","130\n","131\n","132\n","133\n","134\n","135\n","136\n","137\n","138\n","139\n","140\n","141\n","142\n","143\n","144\n","145\n","146\n","147\n","148\n","149\n","150\n","151\n","152\n","153\n","154\n","155\n","156\n","157\n","158\n","159\n","160\n","161\n","162\n","163\n","164\n","165\n","166\n","167\n","168\n","169\n","170\n","171\n","172\n","173\n","174\n","175\n","176\n","177\n","178\n","179\n","180\n","181\n","182\n","183\n","184\n","185\n","186\n","187\n","188\n","189\n","190\n","191\n","192\n","193\n","194\n","195\n","196\n","197\n","198\n","199\n","200\n","201\n","202\n","203\n","204\n","205\n","206\n","207\n","208\n","209\n","210\n","211\n","212\n","213\n","214\n","215\n","216\n","217\n","218\n","219\n","220\n","221\n","222\n","223\n","224\n","225\n","226\n","227\n","228\n","229\n","230\n","231\n","232\n","233\n","234\n","235\n","236\n","237\n","238\n","239\n","240\n","241\n","242\n","243\n","244\n","245\n","246\n","247\n","248\n","249\n","250\n","251\n","252\n","253\n","254\n","255\n","256\n","257\n","258\n","259\n","260\n","261\n","262\n","263\n","264\n","265\n","266\n","267\n","268\n","269\n","270\n","271\n","272\n","273\n","274\n","275\n","276\n","277\n","278\n","279\n","280\n","281\n","282\n","283\n","284\n","285\n","286\n","287\n","288\n","289\n","290\n","291\n","292\n","293\n","294\n","295\n","296\n","297\n","298\n","299\n","300\n","301\n","302\n","303\n","304\n","305\n","306\n","307\n","308\n","309\n","310\n","311\n","312\n","313\n","314\n","315\n","316\n","317\n","318\n","319\n","320\n","321\n","322\n","323\n","324\n","325\n","326\n","327\n","328\n","329\n","330\n","331\n","332\n","333\n","334\n","335\n","336\n","337\n","338\n","339\n","340\n","341\n","342\n","343\n","344\n","345\n","346\n","347\n","348\n","349\n","350\n","351\n","352\n","353\n","354\n","355\n","356\n","357\n","358\n","359\n","360\n","361\n","362\n","363\n","364\n","365\n","366\n","367\n","368\n","369\n","370\n","371\n","372\n","373\n","374\n","375\n","376\n","377\n","378\n","379\n","380\n","381\n","382\n","383\n","384\n","385\n","386\n","387\n","388\n","389\n","390\n","391\n","392\n","393\n","394\n","395\n","396\n","397\n","398\n","399\n","400\n","401\n","402\n","403\n","404\n","405\n","406\n","407\n","408\n","409\n","410\n","411\n","412\n","413\n","414\n","415\n","416\n","417\n","418\n","419\n","420\n","421\n","422\n","423\n","424\n","425\n","426\n","427\n","428\n","429\n","430\n","431\n","432\n","433\n","434\n","435\n","436\n","437\n","438\n","439\n","440\n","441\n","442\n","443\n","444\n","445\n","446\n","447\n","448\n","449\n","450\n","451\n","452\n","453\n","454\n","455\n","456\n","457\n","458\n","459\n","460\n","461\n","462\n","463\n","464\n","465\n","466\n","467\n","468\n","469\n","470\n","471\n","472\n","473\n","474\n","475\n","476\n","477\n","478\n","479\n","480\n","481\n","482\n","483\n","484\n","485\n","486\n","487\n","488\n","489\n","490\n","491\n","492\n","493\n","494\n","495\n","496\n","497\n","498\n","499\n","500\n","501\n","502\n","503\n","504\n","505\n","506\n","507\n","508\n","509\n","510\n","511\n","512\n","513\n"]}],"source":["import os\n","import pickle\n","import numpy as np\n","import pandas as pd\n","import tensorflow as tf\n","import tensorflow_hub as hub\n","\n","from tensorflow.keras.preprocessing.image import load_img, img_to_array\n","from tensorflow.keras.applications.inception_v3 import InceptionV3, preprocess_input\n","from tensorflow.keras.models import Model\n","from tensorflow.keras.layers import Input, Concatenate\n","\n","\n","# Load CSV file with image names and text\n","csv_file = '/content/drive/MyDrive/Project/Final_Dataset/notebooks/proposed model/nuswide/modified_file(1)_shuffled_file.csv'\n","df = pd.read_csv(csv_file)\n","\n","# Initialize InceptionV3 model\n","image_model = InceptionV3(weights='imagenet')\n","image_model = Model(inputs=image_model.input, outputs=image_model.layers[-2].output)\n","\n","# Initialize Universal Sentence Encoder (USE) for text embedding\n","text_model = hub.load(\"https://tfhub.dev/google/universal-sentence-encoder/4\")\n","\n","# Directory containing images\n","image_directory = '/content/drive/MyDrive/Project/Final_Dataset/notebooks/proposed model/nuswide/images'\n","\n","image_features = {}\n","text_features = {}\n","i=1\n","# Process image features\n","for img_name in df['File Name']:\n","    print(i)\n","    i=i+1\n","    img_path = os.path.join(image_directory, img_name)\n","    image = load_img(img_path+'.jpg', target_size=(299, 299))  # InceptionV3 input size\n","    image = img_to_array(image)\n","    image = image.reshape((1, image.shape[0], image.shape[1], image.shape[2]))\n","    image = preprocess_input(image)\n","\n","    feature = image_model.predict(image, verbose=0)\n","\n","    # Extract image ID (assuming image names have an extension, e.g., '.jpg')\n","    image_id = os.path.splitext(img_name)[0]\n","\n","    image_features[image_id] = feature\n","with open('/content/drive/MyDrive/Project/Final_Dataset/notebooks/proposed model/nuswide/imfeatures.pkl', 'wb') as f:\n","    pickle.dump(image_features, f)\n","\n","# Process text features\n","for idx, text in enumerate(df['Text']):\n","    image_id = os.path.splitext(df.loc[idx, 'File Name'])[0]\n","    text_feature = text_model([text])[0].numpy()\n","    text_features[image_id] = text_feature\n","\n","# Merge image and text features\n","all_features = {}\n","for image_id, image_feature in image_features.items():\n","    if image_id in text_features:\n","        text_feature = text_features[image_id]\n","        text_feature = np.expand_dims(text_feature, axis=0)  # Add a new dimension\n","        merged_feature = np.concatenate([image_feature, text_feature], axis=1)\n","        all_features[image_id] = merged_feature\n","\n","\n","# Save merged features dictionary using pickle\n","with open('/content/drive/MyDrive/Project/Final_Dataset/notebooks/proposed model/nuswide/2dmerged_features.pkl', 'wb') as f:\n","    pickle.dump(all_features, f)\n"]},{"cell_type":"code","execution_count":null,"id":"ff6e404c","metadata":{"id":"ff6e404c"},"outputs":[],"source":["import os\n","import pickle\n","import numpy as np\n","import pandas as pd\n","from tensorflow.keras.preprocessing.text import Tokenizer\n","from tensorflow.keras.preprocessing.sequence import pad_sequences\n","from tensorflow.keras.models import Model\n","from tensorflow.keras.utils import to_categorical, plot_model\n","from tensorflow.keras.layers import Input, Dense, LSTM, Embedding, Dropout, add\n","\n","csv_file = '/content/drive/MyDrive/Project/Final_Dataset/notebooks/proposed model/nuswide/modified_file(1)_shuffled_file.csv'\n","df = pd.read_csv(csv_file)\n","\n","# load features from pickle\n","with open('/content/drive/MyDrive/Project/Final_Dataset/notebooks/proposed model/nuswide/2dmerged_features.pkl', 'rb') as f:\n","    features = pickle.load(f)"]},{"cell_type":"code","execution_count":null,"id":"219c2d76","metadata":{"id":"219c2d76","outputId":"93043064-0524-429e-b805-90acb9cc622f","colab":{"base_uri":"https://localhost:8080/"}},"outputs":[{"output_type":"stream","name":"stdout","text":["1973\n"]}],"source":["# create mapping of image to captions\n","mapping = {}\n","# process lines\n","for pre_hashtags,file_name in zip(df['Pre_hashtag'], df['File Name']):\n","    image_id = file_name.split('.')[0]\n","    caption = pre_hashtags\n","    if image_id not in mapping:\n","        mapping[image_id] = []\n","    mapping[image_id].append(caption)\n","\n","#print(\"mapping:\",mapping)\n","\n","def clean(mapping):\n","    for key, captions in mapping.items():\n","        for i in range(len(captions)):\n","            # take one caption at a time\n","            caption = captions[i]\n","            # preprocessing steps\n","            # convert to lowercase\n","            caption = caption.lower()\n","            # del spaceslete digits, special chars, etc.,\n","            caption = caption.replace('[^A-Za-z]', '')\n","            # delete additiona\n","            caption = caption.replace('\\s+', ' ')\n","            # add start and end tags to the caption\n","            caption = 'startseq ' + \" \".join([word for word in caption.split() if len(word)>1]) + ' endseq'\n","            captions[i] = caption\n","\n","clean(mapping)\n","\n","all_captions = []\n","for key in mapping:\n","    for caption in mapping[key]:\n","        all_captions.append(caption)\n","\n","\n","# tokenize the text\n","tokenizer = Tokenizer()\n","tokenizer.fit_on_texts(all_captions)\n","vocab_size = len(tokenizer.word_index) + 1\n","print(vocab_size)\n","\n","# get maximum length of the caption available\n","max_length = max(len(caption.split()) for caption in all_captions)\n","\n","\n","image_ids = list(mapping.keys())\n","split = int(len(image_ids) * 0.80)\n","train = image_ids[:split]\n","test = image_ids[split:]\n","\n","\n","\n","# create data generator to get data in batch (avoids session crash)\n","def data_generator(data_keys, mapping, features, tokenizer, max_length, vocab_size, batch_size):\n","    # loop over images\n","    X1, X2, y = list(), list(), list()\n","    n = 0\n","    while 1:\n","        for key in data_keys:\n","            n += 1\n","            captions = mapping[key]\n","            # process each caption\n","            for caption in captions:\n","                # encode the sequence\n","                seq = tokenizer.texts_to_sequences([caption])[0]\n","                # split the sequence into X, y pairs\n","                for i in range(1, len(seq)):\n","                    # split into input and output pairs\n","                    in_seq, out_seq = seq[:i], seq[i]\n","                    # pad input sequence\n","                    in_seq = pad_sequences([in_seq], maxlen=max_length)[0]\n","                    # encode output sequence\n","                    out_seq = to_categorical([out_seq], num_classes=vocab_size)[0]\n","\n","                    # store the sequences\n","                    X1.append(features[key][0])\n","                    X2.append(in_seq)\n","                    y.append(out_seq)\n","            if n == batch_size:\n","                X1, X2, y = np.array(X1), np.array(X2), np.array(y)\n","                yield [X1, X2], y\n","                X1, X2, y = list(), list(), list()\n","                n = 0\n","\n","\n"]},{"cell_type":"code","execution_count":null,"id":"b59b0adf","metadata":{"id":"b59b0adf","outputId":"e19c3638-cbe8-4411-a6bc-059cd1e68aa3","colab":{"base_uri":"https://localhost:8080/"}},"outputs":[{"output_type":"execute_result","data":{"text/plain":["['0362_235938681',\n"," '0582_2059388222',\n"," '0071_1927191876',\n"," '0377_519527244',\n"," '0386_2594674626',\n"," '0571_743347703',\n"," '0371_70410770',\n"," '0540_2218117161',\n"," '0575_2438358367',\n"," '0266_119222084',\n"," '0529_2375010924',\n"," '0221_290080024',\n"," '0512_1603320950',\n"," '0327_333527157',\n"," '0272_2163942622',\n"," '0449_1468916000',\n"," '0603_122202773',\n"," '0347_1652568146',\n"," '0212_558115514',\n"," '0436_2422243374',\n"," '0524_490459186',\n"," '0399_218847589',\n"," '0519_59778168',\n"," '0394_1759245853',\n"," '0016_2211514225',\n"," '0409_2464143077',\n"," '0526_113741646',\n"," '0052_384443637',\n"," '0524_29141492',\n"," '0059_2176745665',\n"," '0488_430961646',\n"," '0527_233334089',\n"," '0688_409652072',\n"," '0230_760255405',\n"," '0458_248078992',\n"," '0540_387117355',\n"," '0582_2403828106',\n"," '0461_2541290858',\n"," '0520_2570791174',\n"," '0337_534052764',\n"," '0597_352575333',\n"," '0533_2212433904',\n"," '0492_1773149489',\n"," '0537_1591606405',\n"," '0291_291189204',\n"," '0337_183549424',\n"," '0093_64676196',\n"," '0514_2266390201',\n"," '0603_2265198439',\n"," '0421_103156264',\n"," '0543_179649855',\n"," '0213_410523041',\n"," '0442_2107878248',\n"," '0037_307534324',\n"," '0490_123353203',\n"," '0372_278203496',\n"," '0547_2281039140',\n"," '0583_159383299',\n"," '0215_979783194',\n"," '0587_482259687',\n"," '0585_86890464',\n"," '0241_424156697',\n"," '0585_531934179',\n"," '0268_225230260',\n"," '0245_247906127',\n"," '0506_593442932',\n"," '0227_6450232',\n"," '0322_41717831',\n"," '0486_61470101',\n"," '0216_2536418709',\n"," '0310_473563094',\n"," '0431_2232085456',\n"," '0521_1519021979',\n"," '0406_277102818',\n"," '0571_2049492456',\n"," '0509_278770719',\n"," '0360_436659213',\n"," '0034_2627267756',\n"," '0231_299387109',\n"," '0438_95180875',\n"," '0533_256667605',\n"," '0295_383119576',\n"," '0056_182323326',\n"," '0407_117969493',\n"," '0087_302378073',\n"," '0391_95317802',\n"," '0098_2192794779',\n"," '0049_230371163',\n"," '0060_1359951218',\n"," '0650_369670887',\n"," '0004_2097189565',\n"," '0537_2366166',\n"," '0598_2382951202',\n"," '0502_2221924199',\n"," '0535_2298946275',\n"," '0588_251672473',\n"," '0434_2564728013',\n"," '0449_11735980',\n"," '0358_401742731',\n"," '0341_116366108',\n"," '0360_2227695171',\n"," '0254_110465482',\n"," '0022_328182014']"]},"metadata":{},"execution_count":10}],"source":["test"]},{"cell_type":"code","execution_count":null,"id":"23418cf0","metadata":{"id":"23418cf0"},"outputs":[],"source":["import matplotlib.pyplot as plt\n","train_loss = []\n","train_accuracy = []"]},{"cell_type":"code","source":["# encoder model\n","# image feature layers\n","inputs1 = Input(shape=(2560,))\n","fe1 = Dropout(0.5)(inputs1)\n","fe2 = Dense(256, activation='relu')(fe1)\n","# sequence feature layers\n","inputs2 = Input(shape=(None,))\n","se1 = Embedding(vocab_size, 256, mask_zero=True)(inputs2)\n","se2 = Dropout(0.5)(se1)\n","se3 = LSTM(256)(se2)\n","\n","# decoder model\n","decoder1 = add([fe2, se3])\n","decoder2 = Dense(256, activation='relu')(decoder1)\n","outputs = Dense(vocab_size, activation='softmax')(decoder2)\n","\n","model = Model(inputs=[inputs1, inputs2], outputs=outputs)\n","model.compile(loss='categorical_crossentropy', optimizer='adam',metrics=['accuracy'])\n","\n","# train the model\n","epochs = 50\n","\n","batch_size = 24\n","steps = len(train) // batch_size\n","\n","for i in range(epochs):\n","    # create data generator\n","    generator = data_generator(train, mapping, features, tokenizer, max_length, vocab_size, batch_size)\n","    # fit for one epoch\n","    history=model.fit(generator, epochs=1, steps_per_epoch=steps, verbose=1)\n","    train_loss.append(history.history['loss'])\n","    train_accuracy.append(history.history['accuracy'])\n","\n","\n"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"6LreRWBeJT9y","outputId":"5cb27491-e8f2-4b14-b15b-6e0b3703214d"},"id":"6LreRWBeJT9y","execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["17/17 [==============================] - 9s 160ms/step - loss: 7.2380 - accuracy: 0.1503\n","17/17 [==============================] - 4s 231ms/step - loss: 6.4310 - accuracy: 0.1666\n","17/17 [==============================] - 5s 302ms/step - loss: 6.1233 - accuracy: 0.1666\n","17/17 [==============================] - 3s 195ms/step - loss: 5.9277 - accuracy: 0.1682\n","17/17 [==============================] - 2s 145ms/step - loss: 5.6993 - accuracy: 0.1808\n","17/17 [==============================] - 3s 189ms/step - loss: 5.3976 - accuracy: 0.1881\n","17/17 [==============================] - 2s 146ms/step - loss: 5.0436 - accuracy: 0.1918\n","17/17 [==============================] - 3s 147ms/step - loss: 4.5456 - accuracy: 0.1967\n","17/17 [==============================] - 3s 147ms/step - loss: 4.1454 - accuracy: 0.2129\n","17/17 [==============================] - 3s 191ms/step - loss: 3.7533 - accuracy: 0.2365\n","17/17 [==============================] - 2s 146ms/step - loss: 3.4835 - accuracy: 0.2731\n","17/17 [==============================] - 2s 146ms/step - loss: 3.1957 - accuracy: 0.2877\n","17/17 [==============================] - 3s 152ms/step - loss: 2.9382 - accuracy: 0.3190\n","17/17 [==============================] - 3s 193ms/step - loss: 2.4449 - accuracy: 0.3929\n","17/17 [==============================] - 3s 147ms/step - loss: 2.1127 - accuracy: 0.4608\n","17/17 [==============================] - 2s 146ms/step - loss: 1.8225 - accuracy: 0.5002\n","17/17 [==============================] - 3s 179ms/step - loss: 1.5337 - accuracy: 0.5664\n","17/17 [==============================] - 4s 210ms/step - loss: 1.2471 - accuracy: 0.6217\n","17/17 [==============================] - 3s 148ms/step - loss: 1.1364 - accuracy: 0.6489\n","17/17 [==============================] - 3s 148ms/step - loss: 1.0706 - accuracy: 0.6753\n","17/17 [==============================] - 3s 149ms/step - loss: 0.9865 - accuracy: 0.6871\n","17/17 [==============================] - 4s 241ms/step - loss: 0.9180 - accuracy: 0.7017\n","17/17 [==============================] - 3s 148ms/step - loss: 0.8638 - accuracy: 0.7115\n","17/17 [==============================] - 3s 149ms/step - loss: 0.8091 - accuracy: 0.7416\n","17/17 [==============================] - 3s 148ms/step - loss: 0.7351 - accuracy: 0.7578\n","17/17 [==============================] - 3s 169ms/step - loss: 0.6932 - accuracy: 0.7749\n","17/17 [==============================] - 3s 149ms/step - loss: 0.6538 - accuracy: 0.7749\n","17/17 [==============================] - 3s 148ms/step - loss: 0.6563 - accuracy: 0.7777\n","17/17 [==============================] - 3s 147ms/step - loss: 0.6335 - accuracy: 0.7891\n","17/17 [==============================] - 3s 182ms/step - loss: 0.6643 - accuracy: 0.7720\n","17/17 [==============================] - 3s 150ms/step - loss: 0.6318 - accuracy: 0.7960\n","17/17 [==============================] - 3s 149ms/step - loss: 0.6047 - accuracy: 0.8046\n","17/17 [==============================] - 3s 185ms/step - loss: 0.5488 - accuracy: 0.8342\n","17/17 [==============================] - 3s 203ms/step - loss: 0.5095 - accuracy: 0.8444\n","17/17 [==============================] - 3s 150ms/step - loss: 0.4383 - accuracy: 0.8614\n","17/17 [==============================] - 3s 158ms/step - loss: 0.4346 - accuracy: 0.8549\n","17/17 [==============================] - 4s 230ms/step - loss: 0.4794 - accuracy: 0.8338\n","17/17 [==============================] - 3s 148ms/step - loss: 0.4832 - accuracy: 0.8472\n","17/17 [==============================] - 3s 147ms/step - loss: 0.4383 - accuracy: 0.8614\n","17/17 [==============================] - 3s 150ms/step - loss: 0.3689 - accuracy: 0.8842\n","17/17 [==============================] - 4s 212ms/step - loss: 0.2849 - accuracy: 0.9130\n","17/17 [==============================] - 3s 148ms/step - loss: 0.2008 - accuracy: 0.9460\n","17/17 [==============================] - 3s 147ms/step - loss: 0.1508 - accuracy: 0.9614\n","17/17 [==============================] - 3s 147ms/step - loss: 0.1406 - accuracy: 0.9638\n","17/17 [==============================] - 3s 192ms/step - loss: 0.1347 - accuracy: 0.9671\n","17/17 [==============================] - 3s 149ms/step - loss: 0.1272 - accuracy: 0.9630\n","17/17 [==============================] - 3s 148ms/step - loss: 0.1174 - accuracy: 0.9695\n","17/17 [==============================] - 3s 148ms/step - loss: 0.1105 - accuracy: 0.9728\n","17/17 [==============================] - 3s 189ms/step - loss: 0.0992 - accuracy: 0.9760\n","17/17 [==============================] - 3s 198ms/step - loss: 0.0927 - accuracy: 0.9781\n"]}]},{"cell_type":"code","source":["# save the model\n","model.save('/content/drive/MyDrive/Project/Final_Dataset/notebooks/proposed model/nuswide/model_amnn_solution_nuswide_1.h5')"],"metadata":{"id":"pxZrq-P9JzRY"},"id":"pxZrq-P9JzRY","execution_count":null,"outputs":[]},{"cell_type":"code","execution_count":null,"id":"0512cc38","metadata":{"id":"0512cc38","colab":{"base_uri":"https://localhost:8080/","height":774},"outputId":"67a0350d-87ec-4289-f715-32a310523c46"},"outputs":[{"output_type":"error","ename":"ValueError","evalue":"x and y must have same first dimension, but have shapes (50,) and (75, 1)","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)","\u001b[0;32m<ipython-input-23-a3e2e2a6d2c4>\u001b[0m in \u001b[0;36m<cell line: 2>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;31m# Plotting the training loss\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mplt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mplot\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mepochs\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrain_loss\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlabel\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'Training Loss'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m \u001b[0mplt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtitle\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'Training Loss'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0mplt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mxlabel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'Epoch'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0mplt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mylabel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'Loss'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.10/dist-packages/matplotlib/pyplot.py\u001b[0m in \u001b[0;36mplot\u001b[0;34m(scalex, scaley, data, *args, **kwargs)\u001b[0m\n\u001b[1;32m   2810\u001b[0m \u001b[0;34m@\u001b[0m\u001b[0m_copy_docstring_and_deprecators\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mAxes\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mplot\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2811\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0mplot\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mscalex\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mscaley\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2812\u001b[0;31m     return gca().plot(\n\u001b[0m\u001b[1;32m   2813\u001b[0m         \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mscalex\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mscalex\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mscaley\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mscaley\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2814\u001b[0m         **({\"data\": data} if data is not None else {}), **kwargs)\n","\u001b[0;32m/usr/local/lib/python3.10/dist-packages/matplotlib/axes/_axes.py\u001b[0m in \u001b[0;36mplot\u001b[0;34m(self, scalex, scaley, data, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1686\u001b[0m         \"\"\"\n\u001b[1;32m   1687\u001b[0m         \u001b[0mkwargs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcbook\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnormalize_kwargs\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmlines\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mLine2D\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1688\u001b[0;31m         \u001b[0mlines\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_get_lines\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1689\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mline\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mlines\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1690\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0madd_line\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mline\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.10/dist-packages/matplotlib/axes/_base.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, data, *args, **kwargs)\u001b[0m\n\u001b[1;32m    309\u001b[0m                 \u001b[0mthis\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    310\u001b[0m                 \u001b[0margs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 311\u001b[0;31m             yield from self._plot_args(\n\u001b[0m\u001b[1;32m    312\u001b[0m                 this, kwargs, ambiguous_fmt_datakey=ambiguous_fmt_datakey)\n\u001b[1;32m    313\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.10/dist-packages/matplotlib/axes/_base.py\u001b[0m in \u001b[0;36m_plot_args\u001b[0;34m(self, tup, kwargs, return_kwargs, ambiguous_fmt_datakey)\u001b[0m\n\u001b[1;32m    502\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    503\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m!=\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 504\u001b[0;31m             raise ValueError(f\"x and y must have same first dimension, but \"\n\u001b[0m\u001b[1;32m    505\u001b[0m                              f\"have shapes {x.shape} and {y.shape}\")\n\u001b[1;32m    506\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mndim\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0;36m2\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mndim\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0;36m2\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;31mValueError\u001b[0m: x and y must have same first dimension, but have shapes (50,) and (75, 1)"]},{"output_type":"display_data","data":{"text/plain":["<Figure size 640x480 with 1 Axes>"],"image/png":"iVBORw0KGgoAAAANSUhEUgAAAi4AAAGiCAYAAADA0E3hAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjcuMSwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy/bCgiHAAAACXBIWXMAAA9hAAAPYQGoP6dpAAAcw0lEQVR4nO3db2zdVf3A8U/b0VsItEzn2m0WKyiiAhturBYkiKk2gUz3wDjBbHPhj+AkuEZlY7CK6DoRyKIrLkwQH6ibEDDGLUOsLgapWdjWBGSDwMBNYwsT184iLWu/vweG+qvrYLf0z077eiX3wY7n3O+5Hkbf3H8tyLIsCwCABBSO9QYAAI6VcAEAkiFcAIBkCBcAIBnCBQBIhnABAJIhXACAZAgXACAZwgUASIZwAQCSkXe4/OEPf4h58+bF9OnTo6CgIH75y1++5Zpt27bFRz7ykcjlcvG+970v7r///iFsFQCY6PIOl66urpg5c2Y0NTUd0/wXXnghLrvssrjkkkuitbU1vvrVr8ZVV10VjzzySN6bBQAmtoK380sWCwoK4uGHH4758+cfdc6NN94Ymzdvjqeeeqp/7POf/3wcPHgwtm7dOtRLAwAT0KSRvkBLS0vU1tYOGKurq4uvfvWrR13T3d0d3d3d/X/u6+uLV155Jd75zndGQUHBSG0VABhGWZbFoUOHYvr06VFYODxvqx3xcGlra4vy8vIBY+Xl5dHZ2Rn//ve/48QTTzxiTWNjY9x6660jvTUAYBTs378/3v3udw/LfY14uAzFihUror6+vv/PHR0dcdppp8X+/fujtLR0DHcGAByrzs7OqKysjFNOOWXY7nPEw6WioiLa29sHjLW3t0dpaemgz7ZERORyucjlckeMl5aWChcASMxwvs1jxL/HpaamJpqbmweMPfroo1FTUzPSlwYAxpm8w+Vf//pXtLa2Rmtra0T85+POra2tsW/fvoj4z8s8ixYt6p9/7bXXxt69e+Mb3/hG7NmzJ+6+++74xS9+EcuWLRueRwAATBh5h8sTTzwR5513Xpx33nkREVFfXx/nnXderFq1KiIi/v73v/dHTETEe9/73ti8eXM8+uijMXPmzLjzzjvjRz/6UdTV1Q3TQwAAJoq39T0uo6WzszPKysqio6PDe1wAIBEj8fPb7yoCAJIhXACAZAgXACAZwgUASIZwAQCSIVwAgGQIFwAgGcIFAEiGcAEAkiFcAIBkCBcAIBnCBQBIhnABAJIhXACAZAgXACAZwgUASIZwAQCSIVwAgGQIFwAgGcIFAEiGcAEAkiFcAIBkCBcAIBnCBQBIhnABAJIhXACAZAgXACAZwgUASIZwAQCSIVwAgGQIFwAgGcIFAEiGcAEAkiFcAIBkCBcAIBnCBQBIhnABAJIhXACAZAgXACAZwgUASIZwAQCSIVwAgGQIFwAgGcIFAEiGcAEAkiFcAIBkCBcAIBnCBQBIhnABAJIhXACAZAgXACAZwgUASIZwAQCSIVwAgGQIFwAgGcIFAEiGcAEAkiFcAIBkCBcAIBnCBQBIhnABAJIhXACAZAgXACAZQwqXpqamqKqqipKSkqiuro7t27e/6fy1a9fGBz7wgTjxxBOjsrIyli1bFq+99tqQNgwATFx5h8umTZuivr4+GhoaYufOnTFz5syoq6uLl156adD5P/vZz2L58uXR0NAQu3fvjnvvvTc2bdoUN91009vePAAwseQdLnfddVdcffXVsWTJkvjQhz4U69evj5NOOinuu+++Qec//vjjceGFF8YVV1wRVVVV8alPfSouv/zyt3yWBgDgf+UVLj09PbFjx46ora397x0UFkZtbW20tLQMuuaCCy6IHTt29IfK3r17Y8uWLXHppZce9Trd3d3R2dk54AYAMCmfyQcOHIje3t4oLy8fMF5eXh579uwZdM0VV1wRBw4ciI997GORZVkcPnw4rr322jd9qaixsTFuvfXWfLYGAEwAI/6pom3btsXq1avj7rvvjp07d8ZDDz0Umzdvjttuu+2oa1asWBEdHR39t/3794/0NgGABOT1jMuUKVOiqKgo2tvbB4y3t7dHRUXFoGtuueWWWLhwYVx11VUREXHOOedEV1dXXHPNNbFy5cooLDyynXK5XORyuXy2BgBMAHk941JcXByzZ8+O5ubm/rG+vr5obm6OmpqaQde8+uqrR8RJUVFRRERkWZbvfgGACSyvZ1wiIurr62Px4sUxZ86cmDt3bqxduza6urpiyZIlERGxaNGimDFjRjQ2NkZExLx58+Kuu+6K8847L6qrq+O5556LW265JebNm9cfMAAAxyLvcFmwYEG8/PLLsWrVqmhra4tZs2bF1q1b+9+wu2/fvgHPsNx8881RUFAQN998c/ztb3+Ld73rXTFv3rz4zne+M3yPAgCYEAqyBF6v6ezsjLKysujo6IjS0tKx3g4AcAxG4ue331UEACRDuAAAyRAuAEAyhAsAkAzhAgAkQ7gAAMkQLgBAMoQLAJAM4QIAJEO4AADJEC4AQDKECwCQDOECACRDuAAAyRAuAEAyhAsAkAzhAgAkQ7gAAMkQLgBAMoQLAJAM4QIAJEO4AADJEC4AQDKECwCQDOECACRDuAAAyRAuAEAyhAsAkAzhAgAkQ7gAAMkQLgBAMoQLAJAM4QIAJEO4AADJEC4AQDKECwCQDOECACRDuAAAyRAuAEAyhAsAkAzhAgAkQ7gAAMkQLgBAMoQLAJAM4QIAJEO4AADJEC4AQDKECwCQDOECACRDuAAAyRAuAEAyhAsAkAzhAgAkQ7gAAMkQLgBAMoQLAJAM4QIAJEO4AADJEC4AQDKECwCQDOECACRDuAAAyRAuAEAyhhQuTU1NUVVVFSUlJVFdXR3bt29/0/kHDx6MpUuXxrRp0yKXy8WZZ54ZW7ZsGdKGAYCJa1K+CzZt2hT19fWxfv36qK6ujrVr10ZdXV0888wzMXXq1CPm9/T0xCc/+cmYOnVqPPjggzFjxoz4y1/+Eqeeeupw7B8AmEAKsizL8llQXV0d559/fqxbty4iIvr6+qKysjKuv/76WL58+RHz169fH9/73vdiz549ccIJJwxpk52dnVFWVhYdHR1RWlo6pPsAAEbXSPz8zuulop6entixY0fU1tb+9w4KC6O2tjZaWloGXfOrX/0qampqYunSpVFeXh5nn312rF69Onp7e496ne7u7ujs7BxwAwDIK1wOHDgQvb29UV5ePmC8vLw82traBl2zd+/eePDBB6O3tze2bNkSt9xyS9x5553x7W9/+6jXaWxsjLKysv5bZWVlPtsEAMapEf9UUV9fX0ydOjXuueeemD17dixYsCBWrlwZ69evP+qaFStWREdHR/9t//79I71NACABeb05d8qUKVFUVBTt7e0Dxtvb26OiomLQNdOmTYsTTjghioqK+sc++MEPRltbW/T09ERxcfERa3K5XORyuXy2BgBMAHk941JcXByzZ8+O5ubm/rG+vr5obm6OmpqaQddceOGF8dxzz0VfX1//2LPPPhvTpk0bNFoAAI4m75eK6uvrY8OGDfGTn/wkdu/eHdddd110dXXFkiVLIiJi0aJFsWLFiv751113Xbzyyitxww03xLPPPhubN2+O1atXx9KlS4fvUQAAE0Le3+OyYMGCePnll2PVqlXR1tYWs2bNiq1bt/a/YXffvn1RWPjfHqqsrIxHHnkkli1bFueee27MmDEjbrjhhrjxxhuH71EAABNC3t/jMhZ8jwsApGfMv8cFAGAsCRcAIBnCBQBIhnABAJIhXACAZAgXACAZwgUASIZwAQCSIVwAgGQIFwAgGcIFAEiGcAEAkiFcAIBkCBcAIBnCBQBIhnABAJIhXACAZAgXACAZwgUASIZwAQCSIVwAgGQIFwAgGcIFAEiGcAEAkiFcAIBkCBcAIBnCBQBIhnABAJIhXACAZAgXACAZwgUASIZwAQCSIVwAgGQIFwAgGcIFAEiGcAEAkiFcAIBkCBcAIBnCBQBIhnABAJIhXACAZAgXACAZwgUASIZwAQCSIVwAgGQIFwAgGcIFAEiGcAEAkiFcAIBkCBcAIBnCBQBIhnABAJIhXACAZAgXACAZwgUASIZwAQCSIVwAgGQIFwAgGcIFAEiGcAEAkiFcAIBkCBcAIBnCBQBIxpDCpampKaqqqqKkpCSqq6tj+/btx7Ru48aNUVBQEPPnzx/KZQGACS7vcNm0aVPU19dHQ0ND7Ny5M2bOnBl1dXXx0ksvvem6F198Mb72ta/FRRddNOTNAgATW97hctddd8XVV18dS5YsiQ996EOxfv36OOmkk+K+++476pre3t74whe+ELfeemucfvrpb3mN7u7u6OzsHHADAMgrXHp6emLHjh1RW1v73zsoLIza2tpoaWk56rpvfetbMXXq1LjyyiuP6TqNjY1RVlbWf6usrMxnmwDAOJVXuBw4cCB6e3ujvLx8wHh5eXm0tbUNuuaxxx6Le++9NzZs2HDM11mxYkV0dHT03/bv35/PNgGAcWrSSN75oUOHYuHChbFhw4aYMmXKMa/L5XKRy+VGcGcAQIryCpcpU6ZEUVFRtLe3Dxhvb2+PioqKI+Y///zz8eKLL8a8efP6x/r6+v5z4UmT4plnnokzzjhjKPsGACagvF4qKi4ujtmzZ0dzc3P/WF9fXzQ3N0dNTc0R888666x48skno7W1tf/26U9/Oi655JJobW313hUAIC95v1RUX18fixcvjjlz5sTcuXNj7dq10dXVFUuWLImIiEWLFsWMGTOisbExSkpK4uyzzx6w/tRTT42IOGIcAOCt5B0uCxYsiJdffjlWrVoVbW1tMWvWrNi6dWv/G3b37dsXhYW+kBcAGH4FWZZlY72Jt9LZ2RllZWXR0dERpaWlY70dAOAYjMTPb0+NAADJEC4AQDKECwCQDOECACRDuAAAyRAuAEAyhAsAkAzhAgAkQ7gAAMkQLgBAMoQLAJAM4QIAJEO4AADJEC4AQDKECwCQDOECACRDuAAAyRAuAEAyhAsAkAzhAgAkQ7gAAMkQLgBAMoQLAJAM4QIAJEO4AADJEC4AQDKECwCQDOECACRDuAAAyRAuAEAyhAsAkAzhAgAkQ7gAAMkQLgBAMoQLAJAM4QIAJEO4AADJEC4AQDKECwCQDOECACRDuAAAyRAuAEAyhAsAkAzhAgAkQ7gAAMkQLgBAMoQLAJAM4QIAJEO4AADJEC4AQDKECwCQDOECACRDuAAAyRAuAEAyhAsAkAzhAgAkQ7gAAMkQLgBAMoQLAJAM4QIAJEO4AADJEC4AQDKECwCQjCGFS1NTU1RVVUVJSUlUV1fH9u3bjzp3w4YNcdFFF8XkyZNj8uTJUVtb+6bzAQCOJu9w2bRpU9TX10dDQ0Ps3LkzZs6cGXV1dfHSSy8NOn/btm1x+eWXx+9///toaWmJysrK+NSnPhV/+9vf3vbmAYCJpSDLsiyfBdXV1XH++efHunXrIiKir68vKisr4/rrr4/ly5e/5fre3t6YPHlyrFu3LhYtWjTonO7u7uju7u7/c2dnZ1RWVkZHR0eUlpbms10AYIx0dnZGWVnZsP78zusZl56entixY0fU1tb+9w4KC6O2tjZaWlqO6T5effXVeP311+Md73jHUec0NjZGWVlZ/62ysjKfbQIA41Re4XLgwIHo7e2N8vLyAePl5eXR1tZ2TPdx4403xvTp0wfEz/9asWJFdHR09N/279+fzzYBgHFq0mhebM2aNbFx48bYtm1blJSUHHVeLpeLXC43ijsDAFKQV7hMmTIlioqKor29fcB4e3t7VFRUvOnaO+64I9asWRO//e1v49xzz81/pwDAhJfXS0XFxcUxe/bsaG5u7h/r6+uL5ubmqKmpOeq622+/PW677bbYunVrzJkzZ+i7BQAmtLxfKqqvr4/FixfHnDlzYu7cubF27dro6uqKJUuWRETEokWLYsaMGdHY2BgREd/97ndj1apV8bOf/Syqqqr63wtz8sknx8knnzyMDwUAGO/yDpcFCxbEyy+/HKtWrYq2traYNWtWbN26tf8Nu/v27YvCwv8+kfPDH/4wenp64rOf/eyA+2loaIhvfvObb2/3AMCEkvf3uIyFkfgcOAAwssb8e1wAAMaScAEAkiFcAIBkCBcAIBnCBQBIhnABAJIhXACAZAgXACAZwgUASIZwAQCSIVwAgGQIFwAgGcIFAEiGcAEAkiFcAIBkCBcAIBnCBQBIhnABAJIhXACAZAgXACAZwgUASIZwAQCSIVwAgGQIFwAgGcIFAEiGcAEAkiFcAIBkCBcAIBnCBQBIhnABAJIhXACAZAgXACAZwgUASIZwAQCSIVwAgGQIFwAgGcIFAEiGcAEAkiFcAIBkCBcAIBnCBQBIhnABAJIhXACAZAgXACAZwgUASIZwAQCSIVwAgGQIFwAgGcIFAEiGcAEAkiFcAIBkCBcAIBnCBQBIhnABAJIhXACAZAgXACAZwgUASIZwAQCSIVwAgGQIFwAgGcIFAEiGcAEAkiFcAIBkDClcmpqaoqqqKkpKSqK6ujq2b9/+pvMfeOCBOOuss6KkpCTOOeec2LJly5A2CwBMbHmHy6ZNm6K+vj4aGhpi586dMXPmzKirq4uXXnpp0PmPP/54XH755XHllVfGrl27Yv78+TF//vx46qmn3vbmAYCJpSDLsiyfBdXV1XH++efHunXrIiKir68vKisr4/rrr4/ly5cfMX/BggXR1dUVv/71r/vHPvrRj8asWbNi/fr1g16ju7s7uru7+//c0dERp512Wuzfvz9KS0vz2S4AMEY6OzujsrIyDh48GGVlZcNyn5PymdzT0xM7duyIFStW9I8VFhZGbW1ttLS0DLqmpaUl6uvrB4zV1dXFL3/5y6Nep7GxMW699dYjxisrK/PZLgBwHPjHP/4xNuFy4MCB6O3tjfLy8gHj5eXlsWfPnkHXtLW1DTq/ra3tqNdZsWLFgNg5ePBgvOc974l9+/YN2wNnaN6oZ89+jT1ncfxwFscX53H8eOMVk3e84x3Ddp95hctoyeVykcvljhgvKyvzD+FxorS01FkcJ5zF8cNZHF+cx/GjsHD4PsSc1z1NmTIlioqKor29fcB4e3t7VFRUDLqmoqIir/kAAEeTV7gUFxfH7Nmzo7m5uX+sr68vmpubo6amZtA1NTU1A+ZHRDz66KNHnQ8AcDR5v1RUX18fixcvjjlz5sTcuXNj7dq10dXVFUuWLImIiEWLFsWMGTOisbExIiJuuOGGuPjii+POO++Myy67LDZu3BhPPPFE3HPPPcd8zVwuFw0NDYO+fMTochbHD2dx/HAWxxfncfwYibPI++PQERHr1q2L733ve9HW1hazZs2K73//+1FdXR0RER//+Mejqqoq7r///v75DzzwQNx8883x4osvxvvf//64/fbb49JLLx22BwEATAxDChcAgLHgdxUBAMkQLgBAMoQLAJAM4QIAJOO4CZempqaoqqqKkpKSqK6uju3bt7/p/AceeCDOOuusKCkpiXPOOSe2bNkySjsd//I5iw0bNsRFF10UkydPjsmTJ0dtbe1bnh3HLt+/F2/YuHFjFBQUxPz580d2gxNIvmdx8ODBWLp0aUybNi1yuVyceeaZ/j01TPI9i7Vr18YHPvCBOPHEE6OysjKWLVsWr7322ijtdvz6wx/+EPPmzYvp06dHQUHBm/4Owjds27YtPvKRj0Qul4v3ve99Az6BfMyy48DGjRuz4uLi7L777sv+/Oc/Z1dffXV26qmnZu3t7YPO/+Mf/5gVFRVlt99+e/b0009nN998c3bCCSdkTz755CjvfPzJ9yyuuOKKrKmpKdu1a1e2e/fu7Itf/GJWVlaW/fWvfx3lnY8/+Z7FG1544YVsxowZ2UUXXZR95jOfGZ3NjnP5nkV3d3c2Z86c7NJLL80ee+yx7IUXXsi2bduWtba2jvLOx598z+KnP/1plsvlsp/+9KfZCy+8kD3yyCPZtGnTsmXLlo3yzsefLVu2ZCtXrsweeuihLCKyhx9++E3n7927NzvppJOy+vr67Omnn85+8IMfZEVFRdnWrVvzuu5xES5z587Nli5d2v/n3t7ebPr06VljY+Og8z/3uc9ll1122YCx6urq7Etf+tKI7nMiyPcs/tfhw4ezU045JfvJT34yUlucMIZyFocPH84uuOCC7Ec/+lG2ePFi4TJM8j2LH/7wh9npp5+e9fT0jNYWJ4x8z2Lp0qXZJz7xiQFj9fX12YUXXjii+5xojiVcvvGNb2Qf/vCHB4wtWLAgq6ury+taY/5SUU9PT+zYsSNqa2v7xwoLC6O2tjZaWloGXdPS0jJgfkREXV3dUedzbIZyFv/r1Vdfjddff31YfxPoRDTUs/jWt74VU6dOjSuvvHI0tjkhDOUsfvWrX0VNTU0sXbo0ysvL4+yzz47Vq1dHb2/vaG17XBrKWVxwwQWxY8eO/peT9u7dG1u2bPElqGNguH52j/lvhz5w4ED09vZGeXn5gPHy8vLYs2fPoGva2toGnd/W1jZi+5wIhnIW/+vGG2+M6dOnH/EPJ/kZylk89thjce+990Zra+so7HDiGMpZ7N27N373u9/FF77whdiyZUs899xz8eUvfzlef/31aGhoGI1tj0tDOYsrrrgiDhw4EB/72Mciy7I4fPhwXHvttXHTTTeNxpb5f472s7uzszP+/e9/x4knnnhM9zPmz7gwfqxZsyY2btwYDz/8cJSUlIz1diaUQ4cOxcKFC2PDhg0xZcqUsd7OhNfX1xdTp06Ne+65J2bPnh0LFiyIlStXxvr168d6axPOtm3bYvXq1XH33XfHzp0746GHHorNmzfHbbfdNtZbY4jG/BmXKVOmRFFRUbS3tw8Yb29vj4qKikHXVFRU5DWfYzOUs3jDHXfcEWvWrInf/va3ce65547kNieEfM/i+eefjxdffDHmzZvXP9bX1xcREZMmTYpnnnkmzjjjjJHd9Dg1lL8X06ZNixNOOCGKior6xz74wQ9GW1tb9PT0RHFx8YjuebwaylnccsstsXDhwrjqqqsiIuKcc86Jrq6uuOaaa2LlypVRWOi/30fL0X52l5aWHvOzLRHHwTMuxcXFMXv27Ghubu4f6+vri+bm5qipqRl0TU1NzYD5ERGPPvroUedzbIZyFhERt99+e9x2222xdevWmDNnzmhsddzL9yzOOuusePLJJ6O1tbX/9ulPfzouueSSaG1tjcrKytHc/rgylL8XF154YTz33HP98RgR8eyzz8a0adNEy9swlLN49dVXj4iTN4Iy86v6RtWw/ezO733DI2Pjxo1ZLpfL7r///uzpp5/OrrnmmuzUU0/N2trasizLsoULF2bLly/vn//HP/4xmzRpUnbHHXdku3fvzhoaGnwcepjkexZr1qzJiouLswcffDD7+9//3n87dOjQWD2EcSPfs/hfPlU0fPI9i3379mWnnHJK9pWvfCV75plnsl//+tfZ1KlTs29/+9tj9RDGjXzPoqGhITvllFOyn//859nevXuz3/zmN9kZZ5yRfe5znxurhzBuHDp0KNu1a1e2a9euLCKyu+66K9u1a1f2l7/8JcuyLFu+fHm2cOHC/vlvfBz661//erZ79+6sqakp3Y9DZ1mW/eAHP8hOO+20rLi4OJs7d272pz/9qf9/u/jii7PFixcPmP+LX/wiO/PMM7Pi4uLswx/+cLZ58+ZR3vH4lc9ZvOc978ki4ohbQ0PD6G98HMr378X/J1yGV75n8fjjj2fV1dVZLpfLTj/99Ow73/lOdvjw4VHe9fiUz1m8/vrr2Te/+c3sjDPOyEpKSrLKysrsy1/+cvbPf/5z9Dc+zvz+978f9N//b/z/v3jx4uziiy8+Ys2sWbOy4uLi7PTTT89+/OMf533dgizzXBkAkIYxf48LAMCxEi4AQDKECwCQDOECACRDuAAAyRAuAEAyhAsAkAzhAgAkQ7gAAMkQLgBAMoQLAJCM/wM9kKRvAVrZIAAAAABJRU5ErkJggg==\n"},"metadata":{}}],"source":["# Plotting the training loss\n","plt.plot(range(1, epochs+1), train_loss, label='Training Loss')\n","plt.title('Training Loss')\n","plt.xlabel('Epoch')\n","plt.ylabel('Loss')\n","plt.legend()\n","plt.show()\n","\n","# Plotting the training accuracy\n","plt.plot(range(1, epochs+1), train_accuracy, label='Training Accuracy')\n","plt.title('Training Accuracy')\n","plt.xlabel('Epoch')\n","plt.ylabel('Accuracy')\n","plt.legend()\n","plt.show()"]},{"cell_type":"code","source":["test_generator = data_generator(test, mapping, features, tokenizer, max_length, vocab_size, batch_size)\n","test_steps = len(test) // batch_size\n","\n","test_loss = model.evaluate(test_generator, steps=test_steps, verbose=1)\n","print(\"Test Loss:\", test_loss)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"YD_yXCNE9afj","outputId":"cb003779-7096-4654-a454-80e02f18753a"},"id":"YD_yXCNE9afj","execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["4/4 [==============================] - 4s 85ms/step - loss: 19.4690 - accuracy: 0.1858\n","Test Loss: [19.468994140625, 0.1857638955116272]\n"]}]},{"cell_type":"code","source":["import json\n","tokenizer_json = tokenizer.to_json()\n","\n","# Save the tokenizer to a file\n","with open('/content/drive/MyDrive/Project/Final_Dataset/notebooks/proposed model/nuswide/tokenizer (1).json', 'w', encoding='utf-8') as json_file:\n","    json_file.write(tokenizer_json)"],"metadata":{"id":"smIPG0bTi29S"},"id":"smIPG0bTi29S","execution_count":null,"outputs":[]},{"cell_type":"code","source":["import os\n","import os\n","import re\n","import pandas as pd\n","import pickle\n","import pandas as pd\n","from tensorflow.keras.preprocessing.text import Tokenizer\n","from tensorflow.keras.preprocessing.sequence import pad_sequences\n","from tensorflow.keras.models import Model\n","from tensorflow.keras.utils import to_categorical, plot_model\n","from tensorflow.keras.layers import Input, Dense, LSTM, Embedding, Dropout, add\n","import tensorflow as tf\n","import tensorflow_hub as hub\n","from tensorflow.keras.preprocessing.image import load_img, img_to_array\n","from tensorflow.keras.applications.inception_v3 import InceptionV3, preprocess_input\n","from tensorflow.keras.models import Model\n","from tensorflow.keras.layers import Input, Concatenate\n","from tensorflow.keras.preprocessing.text import Tokenizer\n","import json\n","from tensorflow.keras.models import load_model as ld\n","from tkinter import filedialog\n","import json\n","import numpy as np\n","from tensorflow.keras.preprocessing.text import tokenizer_from_json\n","#from cap_gen import generate_caption\n","\n","\n","\n","def idx_to_word(integer, tokenizer):\n","\tfor word, index in tokenizer.word_index.items():\n","\t\tif index == integer:\n","\t\t\treturn word\n","\treturn None\n","\n","# generate caption for an image\n","def predict_hashtag(model, image, tokenizer, max_length):\n","\t# add start tag for generation process\n","\tin_text = 'startseq'\n","\t# iterate over the max length of sequence\n","\tfor i in range(max_length):\n","\t\t# encode input sequence\n","\t\tsequence = tokenizer.texts_to_sequences([in_text])[0]\n","\t\t# pad the sequence\n","\t\tsequence = pad_sequences([sequence], max_length)\n","\t\t# predict next word\n","\t\tyhat = model.predict([image, sequence], verbose=0)\n","\t\t# get index with high probability\n","\t\tyhat = np.argmax(yhat)\n","\t\t# convert index to word\n","\t\tword = idx_to_word(yhat, tokenizer)\n","\t\t# stop if word not found\n","\t\tif word is None:\n","\t\t\tbreak\n","\t\t# append word as input for generating next word\n","\t\tin_text += \" \" + word\n","\t\t# stop if we reach end tag\n","\t\tif word == 'endseq':\n","\t\t\tbreak\n","\n","\treturn in_text\n","\n","\n","\n","if __name__ == \"__main__\":\n","\timage_model = InceptionV3(weights='imagenet')\n","\timage_model = Model(inputs=image_model.input, outputs=image_model.layers[-2].output)\n","\n","\twith open('/content/drive/MyDrive/Project/Final_Dataset/notebooks/proposed model/nuswide/tokenizer (1).json', 'r', encoding='utf-8') as json_file:\n","\t\ttokenizer_json = json_file.read()\n","\n","\ttokenizer = tokenizer_from_json(tokenizer_json)\n","\n","\tmodel = ld('/content/drive/MyDrive/Project/Final_Dataset/notebooks/proposed model/nuswide/model_amnn_solution_nuswide_1.h5')\n","\ttext_model = hub.load(\"https://www.kaggle.com/models/google/universal-sentence-encoder/frameworks/TensorFlow2/variations/universal-sentence-encoder/versions/2\")\n","\n","\ttextt = input(\"Enter some text: \")\n","\ttext_feature = text_model([textt])[0].numpy()\n","\ttext_feature = np.expand_dims(text_feature, axis=0)\n","\n","\timg_path = '/content/car.jpg'\n","\timage = load_img(img_path, target_size=(299, 299))\n","\timage = img_to_array(image)\n","\timage = image.reshape((1, image.shape[0], image.shape[1], image.shape[2]))\n","\timage = preprocess_input(image)\n","\n","\timfeature = image_model.predict(image, verbose=0)\n","\n","\tmerged_feature = np.concatenate([imfeature, text_feature], axis=1)\n","\n","\tpr_h=predict_hashtag(model, merged_feature, tokenizer, 7)\n","\n","\t#print(pr_h)\n","\n","\tpr_h = pr_h.replace(\"startseq\", \"\").replace(\"endseq\", \"\")\n","\n","\twords = pr_h.split()\n","\n","\t# Add '#' to each word\n","\thashtags = ['#' + word.lower() for word in words]\n","\n","\tformatted_output = ' '.join(hashtags)\n","\n","\tprint(formatted_output)\n","\tformatted_output_without_hashtags = formatted_output.replace(\"#\", \"\")\n","\t#print(formatted_output_without_hashtags)\n","\t# predicted_caption = generate_caption(formatted_output_without_hashtags)\n","\t# print(\"Predicted Caption:\", predicted_caption)\n","\n","\t# modified_text = predicted_caption.replace(\"eostok\", \"\")\n","\n","\t# print(modified_text)\n","\n","\n","\n","\n"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"BXAY4cT8gFaQ","outputId":"cf657494-16ae-469a-a960-47e6df3bccbc"},"id":"BXAY4cT8gFaQ","execution_count":null,"outputs":[{"name":"stdout","output_type":"stream","text":["Enter some text: new car\n"]},{"output_type":"stream","name":"stderr","text":["WARNING:tensorflow:5 out of the last 15 calls to <function Model.make_predict_function.<locals>.predict_function at 0x7b43cd2fc3a0> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has reduce_retracing=True option that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n"]},{"output_type":"stream","name":"stdout","text":["#carson #carsgasm #adventureawaits #carsofig #carsi\n"]}]},{"cell_type":"code","source":["import os\n","import os\n","import re\n","import pandas as pd\n","import pickle\n","import pandas as pd\n","from tensorflow.keras.preprocessing.text import Tokenizer\n","from tensorflow.keras.preprocessing.sequence import pad_sequences\n","from tensorflow.keras.models import Model\n","from tensorflow.keras.utils import to_categorical, plot_model\n","from tensorflow.keras.layers import Input, Dense, LSTM, Embedding, Dropout, add\n","import tensorflow as tf\n","import tensorflow_hub as hub\n","from tensorflow.keras.preprocessing.image import load_img, img_to_array\n","from tensorflow.keras.applications.inception_v3 import InceptionV3, preprocess_input\n","from tensorflow.keras.models import Model\n","from tensorflow.keras.layers import Input, Concatenate\n","from tensorflow.keras.preprocessing.text import Tokenizer\n","import json\n","from tensorflow.keras.models import load_model as ld\n","from tkinter import filedialog\n","import json\n","import numpy as np\n","from tensorflow.keras.preprocessing.text import tokenizer_from_json\n","#from cap_gen import generate_caption\n","\n","\n","\n","def idx_to_word(integer, tokenizer):\n","\tfor word, index in tokenizer.word_index.items():\n","\t\tif index == integer:\n","\t\t\treturn word\n","\treturn None\n","\n","# generate caption for an image\n","def predict_hashtag(model, image, tokenizer, max_length):\n","\t# add start tag for generation process\n","\tin_text = 'startseq'\n","\t# iterate over the max length of sequence\n","\tfor i in range(max_length):\n","\t\t# encode input sequence\n","\t\tsequence = tokenizer.texts_to_sequences([in_text])[0]\n","\t\t# pad the sequence\n","\t\tsequence = pad_sequences([sequence], max_length)\n","\t\t# predict next word\n","\t\tyhat = model.predict([image, sequence], verbose=0)\n","\t\t# get index with high probability\n","\t\tyhat = np.argmax(yhat)\n","\t\t# convert index to word\n","\t\tword = idx_to_word(yhat, tokenizer)\n","\t\t# stop if word not found\n","\t\tif word is None:\n","\t\t\tbreak\n","\t\t# append word as input for generating next word\n","\t\tin_text += \" \" + word\n","\t\t# stop if we reach end tag\n","\t\tif word == 'endseq':\n","\t\t\tbreak\n","\n","\treturn in_text\n","\n","\n","\n","if __name__ == \"__main__\":\n","\timage_model = InceptionV3(weights='imagenet')\n","\timage_model = Model(inputs=image_model.input, outputs=image_model.layers[-2].output)\n","\n","\twith open('/content/drive/MyDrive/Project/Final_Dataset/notebooks/proposed model/nuswide/tokenizer (1).json', 'r', encoding='utf-8') as json_file:\n","\t\ttokenizer_json = json_file.read()\n","\n","\ttokenizer = tokenizer_from_json(tokenizer_json)\n","\n","\tmodel = ld('/content/drive/MyDrive/Project/Final_Dataset/notebooks/proposed model/nuswide/model_amnn_solution_nuswide_1.h5')\n","\ttext_model = hub.load(\"https://www.kaggle.com/models/google/universal-sentence-encoder/frameworks/TensorFlow2/variations/universal-sentence-encoder/versions/2\")\n","\n","\ttextt = input(\"Enter some text: \")\n","\ttext_feature = text_model([textt])[0].numpy()\n","\ttext_feature = np.expand_dims(text_feature, axis=0)\n","\n","\timg_path = '/content/catbuilding.jpg'\n","\timage = load_img(img_path, target_size=(299, 299))\n","\timage = img_to_array(image)\n","\timage = image.reshape((1, image.shape[0], image.shape[1], image.shape[2]))\n","\timage = preprocess_input(image)\n","\n","\timfeature = image_model.predict(image, verbose=0)\n","\n","\tmerged_feature = np.concatenate([imfeature, text_feature], axis=1)\n","\n","\tpr_h=predict_hashtag(model, merged_feature, tokenizer, 7)\n","\n","\t#print(pr_h)\n","\n","\tpr_h = pr_h.replace(\"startseq\", \"\").replace(\"endseq\", \"\")\n","\n","\twords = pr_h.split()\n","\n","\t# Add '#' to each word\n","\thashtags = ['#' + word.lower() for word in words]\n","\n","\tformatted_output = ' '.join(hashtags)\n","\n","\tprint(formatted_output)\n","\tformatted_output_without_hashtags = formatted_output.replace(\"#\", \"\")\n","\t#print(formatted_output_without_hashtags)\n","\t# predicted_caption = generate_caption(formatted_output_without_hashtags)\n","\t# print(\"Predicted Caption:\", predicted_caption)\n","\n","\t# modified_text = predicted_caption.replace(\"eostok\", \"\")\n","\n","\t# print(modified_text)\n","\n","\n","\n","\n"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"NZoZyvgFKsUk","outputId":"4d6a205a-26bf-4938-8ed8-44373ff20cd2"},"id":"NZoZyvgFKsUk","execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Enter some text: cat and city\n","#catlifegoals #catlifegoals #carswithoutlimits #carspotting #carstagram\n"]}]},{"cell_type":"code","source":["import os\n","import os\n","import re\n","import pandas as pd\n","import pickle\n","import pandas as pd\n","from tensorflow.keras.preprocessing.text import Tokenizer\n","from tensorflow.keras.preprocessing.sequence import pad_sequences\n","from tensorflow.keras.models import Model\n","from tensorflow.keras.utils import to_categorical, plot_model\n","from tensorflow.keras.layers import Input, Dense, LSTM, Embedding, Dropout, add\n","import tensorflow as tf\n","import tensorflow_hub as hub\n","from tensorflow.keras.preprocessing.image import load_img, img_to_array\n","from tensorflow.keras.applications.inception_v3 import InceptionV3, preprocess_input\n","from tensorflow.keras.models import Model\n","from tensorflow.keras.layers import Input, Concatenate\n","from tensorflow.keras.preprocessing.text import Tokenizer\n","import json\n","from tensorflow.keras.models import load_model as ld\n","from tkinter import filedialog\n","import json\n","import numpy as np\n","from tensorflow.keras.preprocessing.text import tokenizer_from_json\n","#from cap_gen import generate_caption\n","\n","\n","\n","def idx_to_word(integer, tokenizer):\n","\tfor word, index in tokenizer.word_index.items():\n","\t\tif index == integer:\n","\t\t\treturn word\n","\treturn None\n","\n","# generate caption for an image\n","def predict_hashtag(model, image, tokenizer, max_length):\n","\t# add start tag for generation process\n","\tin_text = 'startseq'\n","\t# iterate over the max length of sequence\n","\tfor i in range(max_length):\n","\t\t# encode input sequence\n","\t\tsequence = tokenizer.texts_to_sequences([in_text])[0]\n","\t\t# pad the sequence\n","\t\tsequence = pad_sequences([sequence], max_length)\n","\t\t# predict next word\n","\t\tyhat = model.predict([image, sequence], verbose=0)\n","\t\t# get index with high probability\n","\t\tyhat = np.argmax(yhat)\n","\t\t# convert index to word\n","\t\tword = idx_to_word(yhat, tokenizer)\n","\t\t# stop if word not found\n","\t\tif word is None:\n","\t\t\tbreak\n","\t\t# append word as input for generating next word\n","\t\tin_text += \" \" + word\n","\t\t# stop if we reach end tag\n","\t\tif word == 'endseq':\n","\t\t\tbreak\n","\n","\treturn in_text\n","\n","\n","\n","if __name__ == \"__main__\":\n","\timage_model = InceptionV3(weights='imagenet')\n","\timage_model = Model(inputs=image_model.input, outputs=image_model.layers[-2].output)\n","\n","\twith open('/content/drive/MyDrive/Project/Final_Dataset/notebooks/proposed model/nuswide/tokenizer (1).json', 'r', encoding='utf-8') as json_file:\n","\t\ttokenizer_json = json_file.read()\n","\n","\ttokenizer = tokenizer_from_json(tokenizer_json)\n","\n","\tmodel = ld('/content/drive/MyDrive/Project/Final_Dataset/notebooks/proposed model/nuswide/model_amnn_solution_nuswide_1.h5')\n","\ttext_model = hub.load(\"https://www.kaggle.com/models/google/universal-sentence-encoder/frameworks/TensorFlow2/variations/universal-sentence-encoder/versions/2\")\n","\n","\ttextt = input(\"Enter some text: \")\n","\ttext_feature = text_model([textt])[0].numpy()\n","\ttext_feature = np.expand_dims(text_feature, axis=0)\n","\n","\timg_path = '/content/beach.jpg'\n","\timage = load_img(img_path, target_size=(299, 299))\n","\timage = img_to_array(image)\n","\timage = image.reshape((1, image.shape[0], image.shape[1], image.shape[2]))\n","\timage = preprocess_input(image)\n","\n","\timfeature = image_model.predict(image, verbose=0)\n","\n","\tmerged_feature = np.concatenate([imfeature, text_feature], axis=1)\n","\n","\tpr_h=predict_hashtag(model, merged_feature, tokenizer, 7)\n","\n","\t#print(pr_h)\n","\n","\tpr_h = pr_h.replace(\"startseq\", \"\").replace(\"endseq\", \"\")\n","\n","\twords = pr_h.split()\n","\n","\t# Add '#' to each word\n","\thashtags = ['#' + word.lower() for word in words]\n","\n","\tformatted_output = ' '.join(hashtags)\n","\n","\tprint(formatted_output)\n","\tformatted_output_without_hashtags = formatted_output.replace(\"#\", \"\")\n","\t#print(formatted_output_without_hashtags)\n","\t# predicted_caption = generate_caption(formatted_output_without_hashtags)\n","\t# print(\"Predicted Caption:\", predicted_caption)\n","\n","\t# modified_text = predicted_caption.replace(\"eostok\", \"\")\n","\n","\t# print(modified_text)\n","\n","\n","\n","\n"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"ojt_fQQNbwCI","outputId":"e42e2a44-deb7-4c3a-cd76-93a5b5bd5c71"},"id":"ojt_fQQNbwCI","execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Enter some text: happy day\n","#beachlife #beachdays #seashells #wavewatcher #summerdays\n"]}]},{"cell_type":"code","source":["import os\n","import os\n","import re\n","import pandas as pd\n","import pickle\n","import pandas as pd\n","from tensorflow.keras.preprocessing.text import Tokenizer\n","from tensorflow.keras.preprocessing.sequence import pad_sequences\n","from tensorflow.keras.models import Model\n","from tensorflow.keras.utils import to_categorical, plot_model\n","from tensorflow.keras.layers import Input, Dense, LSTM, Embedding, Dropout, add\n","import tensorflow as tf\n","import tensorflow_hub as hub\n","from tensorflow.keras.preprocessing.image import load_img, img_to_array\n","from tensorflow.keras.applications.inception_v3 import InceptionV3, preprocess_input\n","from tensorflow.keras.models import Model\n","from tensorflow.keras.layers import Input, Concatenate\n","from tensorflow.keras.preprocessing.text import Tokenizer\n","import json\n","from tensorflow.keras.models import load_model as ld\n","from tkinter import filedialog\n","import json\n","import numpy as np\n","from tensorflow.keras.preprocessing.text import tokenizer_from_json\n","#from cap_gen import generate_caption\n","\n","\n","\n","def idx_to_word(integer, tokenizer):\n","\tfor word, index in tokenizer.word_index.items():\n","\t\tif index == integer:\n","\t\t\treturn word\n","\treturn None\n","\n","# generate caption for an image\n","def predict_hashtag(model, image, tokenizer, max_length):\n","\t# add start tag for generation process\n","\tin_text = 'startseq'\n","\t# iterate over the max length of sequence\n","\tfor i in range(max_length):\n","\t\t# encode input sequence\n","\t\tsequence = tokenizer.texts_to_sequences([in_text])[0]\n","\t\t# pad the sequence\n","\t\tsequence = pad_sequences([sequence], max_length)\n","\t\t# predict next word\n","\t\tyhat = model.predict([image, sequence], verbose=0)\n","\t\t# get index with high probability\n","\t\tyhat = np.argmax(yhat)\n","\t\t# convert index to word\n","\t\tword = idx_to_word(yhat, tokenizer)\n","\t\t# stop if word not found\n","\t\tif word is None:\n","\t\t\tbreak\n","\t\t# append word as input for generating next word\n","\t\tin_text += \" \" + word\n","\t\t# stop if we reach end tag\n","\t\tif word == 'endseq':\n","\t\t\tbreak\n","\n","\treturn in_text\n","\n","\n","\n","if __name__ == \"__main__\":\n","\timage_model = InceptionV3(weights='imagenet')\n","\timage_model = Model(inputs=image_model.input, outputs=image_model.layers[-2].output)\n","\n","\twith open('/content/drive/MyDrive/Project/Final_Dataset/notebooks/proposed model/nuswide/tokenizer (1).json', 'r', encoding='utf-8') as json_file:\n","\t\ttokenizer_json = json_file.read()\n","\n","\ttokenizer = tokenizer_from_json(tokenizer_json)\n","\n","\tmodel = ld('/content/drive/MyDrive/Project/Final_Dataset/notebooks/proposed model/nuswide/model_amnn_solution_nuswide_1.h5')\n","\ttext_model = hub.load(\"https://www.kaggle.com/models/google/universal-sentence-encoder/frameworks/TensorFlow2/variations/universal-sentence-encoder/versions/2\")\n","\n","\ttextt = input(\"Enter some text: \")\n","\ttext_feature = text_model([textt])[0].numpy()\n","\ttext_feature = np.expand_dims(text_feature, axis=0)\n","\n","\timg_path = '/content/bookbeach.jpg'\n","\timage = load_img(img_path, target_size=(299, 299))\n","\timage = img_to_array(image)\n","\timage = image.reshape((1, image.shape[0], image.shape[1], image.shape[2]))\n","\timage = preprocess_input(image)\n","\n","\timfeature = image_model.predict(image, verbose=0)\n","\n","\tmerged_feature = np.concatenate([imfeature, text_feature], axis=1)\n","\n","\tpr_h=predict_hashtag(model, merged_feature, tokenizer, 7)\n","\n","\t#print(pr_h)\n","\n","\tpr_h = pr_h.replace(\"startseq\", \"\").replace(\"endseq\", \"\")\n","\n","\twords = pr_h.split()\n","\n","\t# Add '#' to each word\n","\thashtags = ['#' + word.lower() for word in words]\n","\n","\tformatted_output = ' '.join(hashtags)\n","\n","\tprint(formatted_output)\n","\tformatted_output_without_hashtags = formatted_output.replace(\"#\", \"\")\n","\t#print(formatted_output_without_hashtags)\n","\t# predicted_caption = generate_caption(formatted_output_without_hashtags)\n","\t# print(\"Predicted Caption:\", predicted_caption)\n","\n","\t# modified_text = predicted_caption.replace(\"eostok\", \"\")\n","\n","\t# print(modified_text)\n","\n","\n","\n","\n"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"jECtXzlCMYcn","outputId":"c8747155-7368-4234-9f3a-698c5eacc1a0"},"id":"jECtXzlCMYcn","execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Enter some text: read time\n","#explorewithvehicle #beautifulceremony #wavewatcher #wavewatcher #coastalescape\n"]}]},{"cell_type":"code","source":["import os\n","import os\n","import re\n","import pandas as pd\n","import pickle\n","import pandas as pd\n","from tensorflow.keras.preprocessing.text import Tokenizer\n","from tensorflow.keras.preprocessing.sequence import pad_sequences\n","from tensorflow.keras.models import Model\n","from tensorflow.keras.utils import to_categorical, plot_model\n","from tensorflow.keras.layers import Input, Dense, LSTM, Embedding, Dropout, add\n","import tensorflow as tf\n","import tensorflow_hub as hub\n","from tensorflow.keras.preprocessing.image import load_img, img_to_array\n","from tensorflow.keras.applications.inception_v3 import InceptionV3, preprocess_input\n","from tensorflow.keras.models import Model\n","from tensorflow.keras.layers import Input, Concatenate\n","from tensorflow.keras.preprocessing.text import Tokenizer\n","import json\n","from tensorflow.keras.models import load_model as ld\n","from tkinter import filedialog\n","import json\n","import numpy as np\n","from tensorflow.keras.preprocessing.text import tokenizer_from_json\n","#from cap_gen import generate_caption\n","\n","\n","\n","def idx_to_word(integer, tokenizer):\n","\tfor word, index in tokenizer.word_index.items():\n","\t\tif index == integer:\n","\t\t\treturn word\n","\treturn None\n","\n","# generate caption for an image\n","def predict_hashtag(model, image, tokenizer, max_length):\n","\t# add start tag for generation process\n","\tin_text = 'startseq'\n","\t# iterate over the max length of sequence\n","\tfor i in range(max_length):\n","\t\t# encode input sequence\n","\t\tsequence = tokenizer.texts_to_sequences([in_text])[0]\n","\t\t# pad the sequence\n","\t\tsequence = pad_sequences([sequence], max_length)\n","\t\t# predict next word\n","\t\tyhat = model.predict([image, sequence], verbose=0)\n","\t\t# get index with high probability\n","\t\tyhat = np.argmax(yhat)\n","\t\t# convert index to word\n","\t\tword = idx_to_word(yhat, tokenizer)\n","\t\t# stop if word not found\n","\t\tif word is None:\n","\t\t\tbreak\n","\t\t# append word as input for generating next word\n","\t\tin_text += \" \" + word\n","\t\t# stop if we reach end tag\n","\t\tif word == 'endseq':\n","\t\t\tbreak\n","\n","\treturn in_text\n","\n","\n","\n","if __name__ == \"__main__\":\n","\timage_model = InceptionV3(weights='imagenet')\n","\timage_model = Model(inputs=image_model.input, outputs=image_model.layers[-2].output)\n","\n","\twith open('/content/drive/MyDrive/Project/Final_Dataset/notebooks/proposed model/nuswide/tokenizer (1).json', 'r', encoding='utf-8') as json_file:\n","\t\ttokenizer_json = json_file.read()\n","\n","\ttokenizer = tokenizer_from_json(tokenizer_json)\n","\n","\tmodel = ld('/content/drive/MyDrive/Project/Final_Dataset/notebooks/proposed model/nuswide/model_amnn_solution_nuswide_1.h5')\n","\ttext_model = hub.load(\"https://www.kaggle.com/models/google/universal-sentence-encoder/frameworks/TensorFlow2/variations/universal-sentence-encoder/versions/2\")\n","\n","\ttextt = input(\"Enter some text: \")\n","\ttext_feature = text_model([textt])[0].numpy()\n","\ttext_feature = np.expand_dims(text_feature, axis=0)\n","\n","\timg_path = '/content/beachdog.jpg'\n","\timage = load_img(img_path, target_size=(299, 299))\n","\timage = img_to_array(image)\n","\timage = image.reshape((1, image.shape[0], image.shape[1], image.shape[2]))\n","\timage = preprocess_input(image)\n","\n","\timfeature = image_model.predict(image, verbose=0)\n","\n","\tmerged_feature = np.concatenate([imfeature, text_feature], axis=1)\n","\n","\tpr_h=predict_hashtag(model, merged_feature, tokenizer, 7)\n","\n","\t#print(pr_h)\n","\n","\tpr_h = pr_h.replace(\"startseq\", \"\").replace(\"endseq\", \"\")\n","\n","\twords = pr_h.split()\n","\n","\t# Add '#' to each word\n","\thashtags = ['#' + word.lower() for word in words]\n","\n","\tformatted_output = ' '.join(hashtags)\n","\n","\tprint(formatted_output)\n","\tformatted_output_without_hashtags = formatted_output.replace(\"#\", \"\")\n","\t#print(formatted_output_without_hashtags)\n","\t# predicted_caption = generate_caption(formatted_output_without_hashtags)\n","\t# print(\"Predicted Caption:\", predicted_caption)\n","\n","\t# modified_text = predicted_caption.replace(\"eostok\", \"\")\n","\n","\t# print(modified_text)\n","\n","\n","\n","\n"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"YZ6OqOWdcF7f","outputId":"42454348-c664-449e-ae51-86cb3618d035"},"id":"YZ6OqOWdcF7f","execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Enter some text: best bet ever\n","#explorewithvehicle #wildlife #nature #doggylove #adventurebuddies\n"]}]},{"cell_type":"code","source":["def precision_score(test_y, pred_y, k=1):\n","    p_score = []\n","\n","    for i in range(len(test_y)):\n","        # print(pred_y[i][-k:])\n","        # print(pred_y[i][-k])\n","        # result_at_topk = pred_y[i][-k:]\n","        count = 0\n","        for j in range(0,k):\n","            if(pred_y[i][j] in test_y[i]):\n","                count+=1\n","        p_score.append(float(count) / float(k))\n","            # if j in test_y[i]:\n","                # count += 1\n","        # p_score.append(float(count) / float(k))\n","\n","    return np.mean(p_score)\n","\n","def recall_score(test_y, pred_y, k=1):\n","    r_score = []\n","    for i in range(len(test_y)):\n","        count = 0\n","        end=min(k,len(pred_y[i]))\n","        for j in range(0,end):\n","            if(pred_y[i][j] in test_y[i]):\n","                count+=1\n","        r_score.append(float(count) / float(len(test_y[i])))\n","\n","    return np.mean(r_score)\n","\n","\n","precision = precision_score(test_y, pred_y, k=1)\n","recall = recall_score(test_y, pred_y, k=1)\n","\n","# Print precision and recall values\n","print(\"Precision @ 1:\", precision)\n","print(\"Recall @ 1:\", recall)"],"metadata":{"id":"doLQg-q69glr","colab":{"base_uri":"https://localhost:8080/","height":211},"outputId":"e7714f54-9f87-425f-9ad8-d0e594daca69"},"id":"doLQg-q69glr","execution_count":null,"outputs":[{"output_type":"error","ename":"NameError","evalue":"name 'test_y' is not defined","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)","\u001b[0;32m<ipython-input-25-6c5670396cf8>\u001b[0m in \u001b[0;36m<cell line: 32>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     30\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     31\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 32\u001b[0;31m \u001b[0mprecision\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mprecision_score\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtest_y\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpred_y\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mk\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     33\u001b[0m \u001b[0mrecall\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mrecall_score\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtest_y\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpred_y\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mk\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     34\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;31mNameError\u001b[0m: name 'test_y' is not defined"]}]},{"cell_type":"code","source":["y_true = []\n","\n","#print(\"Hashtags for image ID\", image_id, \":\", hashtags)\n","for image_id in test:\n","  print(image_id)\n","  row = df[df['File Name'] == image_id+'.jpg']\n","  hashtags = row['Pre_hashtag'].values[0]\n","  print(hashtags)\n","  y_true.append(hashtags)\n"],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":228},"id":"3u8MpO-OX1ix","outputId":"d268af91-4a78-4293-d156-56828caf480d"},"id":"3u8MpO-OX1ix","execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["0098_2192794779\n"]},{"output_type":"error","ename":"IndexError","evalue":"index 0 is out of bounds for axis 0 with size 0","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mIndexError\u001b[0m                                Traceback (most recent call last)","\u001b[0;32m<ipython-input-19-41c284806cb6>\u001b[0m in \u001b[0;36m<cell line: 4>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      5\u001b[0m   \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mimage_id\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m   \u001b[0mrow\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdf\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mdf\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'File Name'\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0mimage_id\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0;34m'.jpg'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 7\u001b[0;31m   \u001b[0mhashtags\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mrow\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'Pre_hashtag'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      8\u001b[0m   \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mhashtags\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      9\u001b[0m   \u001b[0my_true\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mhashtags\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;31mIndexError\u001b[0m: index 0 is out of bounds for axis 0 with size 0"]}]},{"cell_type":"code","source":["precision = precision_score(y_true, y_pred, average='weighted')\n","recall = recall_score(y_true, y_pred, average='weighted')\n","\n","print(\"Precision:\", precision)\n","print(\"Recall:\", recall)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":211},"id":"hYQh5HzuTPN0","outputId":"af725af4-671d-4d74-f8ac-c5cd17c380b3"},"id":"hYQh5HzuTPN0","execution_count":null,"outputs":[{"output_type":"error","ename":"NameError","evalue":"name 'y_pred' is not defined","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)","\u001b[0;32m<ipython-input-20-39da60bbe968>\u001b[0m in \u001b[0;36m<cell line: 1>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mprecision\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mprecision_score\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my_true\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_pred\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maverage\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'weighted'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0mrecall\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mrecall_score\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my_true\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_pred\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maverage\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'weighted'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Precision:\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mprecision\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Recall:\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrecall\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;31mNameError\u001b[0m: name 'y_pred' is not defined"]}]},{"cell_type":"code","source":["row = df[df['File Name'] == '1.jpg']\n","print(row['Pre_Hashtags'].values[0])"],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":478},"id":"CBb1d8CRXnwA","outputId":"0d59bc45-00be-4906-8bc7-510a515aa753"},"id":"CBb1d8CRXnwA","execution_count":null,"outputs":[{"output_type":"error","ename":"KeyError","evalue":"'Pre_Hashtags'","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)","\u001b[0;32m/usr/local/lib/python3.10/dist-packages/pandas/core/indexes/base.py\u001b[0m in \u001b[0;36mget_loc\u001b[0;34m(self, key)\u001b[0m\n\u001b[1;32m   3652\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 3653\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_engine\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_loc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcasted_key\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   3654\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mKeyError\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0merr\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.10/dist-packages/pandas/_libs/index.pyx\u001b[0m in \u001b[0;36mpandas._libs.index.IndexEngine.get_loc\u001b[0;34m()\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.10/dist-packages/pandas/_libs/index.pyx\u001b[0m in \u001b[0;36mpandas._libs.index.IndexEngine.get_loc\u001b[0;34m()\u001b[0m\n","\u001b[0;32mpandas/_libs/hashtable_class_helper.pxi\u001b[0m in \u001b[0;36mpandas._libs.hashtable.PyObjectHashTable.get_item\u001b[0;34m()\u001b[0m\n","\u001b[0;32mpandas/_libs/hashtable_class_helper.pxi\u001b[0m in \u001b[0;36mpandas._libs.hashtable.PyObjectHashTable.get_item\u001b[0;34m()\u001b[0m\n","\u001b[0;31mKeyError\u001b[0m: 'Pre_Hashtags'","\nThe above exception was the direct cause of the following exception:\n","\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)","\u001b[0;32m<ipython-input-21-a05bb57907f8>\u001b[0m in \u001b[0;36m<cell line: 2>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0mrow\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdf\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mdf\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'File Name'\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m'1.jpg'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrow\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'Pre_Hashtags'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m","\u001b[0;32m/usr/local/lib/python3.10/dist-packages/pandas/core/frame.py\u001b[0m in \u001b[0;36m__getitem__\u001b[0;34m(self, key)\u001b[0m\n\u001b[1;32m   3759\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcolumns\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnlevels\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3760\u001b[0m                 \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_getitem_multilevel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 3761\u001b[0;31m             \u001b[0mindexer\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcolumns\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_loc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   3762\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mis_integer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mindexer\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3763\u001b[0m                 \u001b[0mindexer\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mindexer\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.10/dist-packages/pandas/core/indexes/base.py\u001b[0m in \u001b[0;36mget_loc\u001b[0;34m(self, key)\u001b[0m\n\u001b[1;32m   3653\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_engine\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_loc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcasted_key\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3654\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mKeyError\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0merr\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 3655\u001b[0;31m             \u001b[0;32mraise\u001b[0m \u001b[0mKeyError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0merr\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   3656\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mTypeError\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3657\u001b[0m             \u001b[0;31m# If we have a listlike key, _check_indexing_error will raise\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;31mKeyError\u001b[0m: 'Pre_Hashtags'"]}]},{"cell_type":"code","source":[],"metadata":{"id":"hW6RkEw82AOK"},"id":"hW6RkEw82AOK","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"display_name":"Python 3 (ipykernel)","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.11.5"},"colab":{"provenance":[]}},"nbformat":4,"nbformat_minor":5}